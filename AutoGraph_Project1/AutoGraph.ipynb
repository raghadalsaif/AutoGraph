{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fdaeb49-21fe-4794-be19-fe33db89d7b0",
   "metadata": {},
   "source": [
    "# AutoGraph Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349ee0b-1dfb-41ed-a7fb-4299d3a4e590",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Required Python Packages\n",
    "- `nltk`\n",
    "- `tabula-py`\n",
    "- `autocorrect`\n",
    "- `contractions`\n",
    "- `matplotlib`\n",
    "\n",
    "Run the following cell to install the packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210c39e-cbf9-493a-a73f-8775e5774aad",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c679b9a7-a568-4edb-ba87-961e94d283e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/homebrew/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: tabula-py in /opt/homebrew/anaconda3/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from tabula-py) (2.1.4)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from tabula-py) (1.26.4)\n",
      "Requirement already satisfied: distro in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from tabula-py) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "Requirement already satisfied: autocorrect in /opt/homebrew/anaconda3/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: contractions in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install NLTK library for natural language processing\n",
    "!pip install nltk\n",
    "\n",
    "# Install tabula-py library for extracting tables from PDFs\n",
    "!pip install tabula-py\n",
    "\n",
    "# Install autocorrect library for spell checking\n",
    "!pip install autocorrect\n",
    "\n",
    "#This library is used for expanding contractions (e.g., converting \"can't\" to \"cannot\").\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da72eec-7c8d-4494-90ef-0d0655ca05bc",
   "metadata": {},
   "source": [
    "# User input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2a9c0b0-a98f-479c-ad24-30a141e29ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter the text directly\n",
    "text = \"Your text goes here. You can enter multiple sentences or paragraphs.\"\n",
    "\n",
    "# Create a DataFrame with one column named 'text'\n",
    "df = pd.DataFrame({'text': [text]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f09ff-d6f1-403d-8e14-ec0a5734d6b8",
   "metadata": {},
   "source": [
    "# Data Pre-processing \n",
    "\n",
    "## Steps in the Data Pre-processing \n",
    "\n",
    "1. Lowercasing\n",
    "2. Tokenization\n",
    "3. Removing Punctuation\n",
    "4. Removing Stopwords\n",
    "5. Lemmatization\n",
    "6. Spell Checking\n",
    "7. Joining the tokens back into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "249b9f80-c902-40a0-af55-cb23c7f71690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8919962-288a-4258-b933-ea513e285383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text go enter multiple sentence paragraph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/raghad_alsaif/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raghad_alsaif/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/raghad_alsaif/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\n",
    "# Enter the text directly\n",
    "text = \"\"\"Your text goes here. You can enter multiple sentences or paragraphs.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Expansion of contractions\n",
    "    expanded_words = []    \n",
    "    for word in text.split():\n",
    "        expanded_words.append(contractions.fix(word))   \n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(expanded_text)\n",
    "\n",
    "    # Removing Punctuation\n",
    "    tokens = [token for token in tokens if token not in punctuation]\n",
    "\n",
    "    # Removing Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Removing Special Characters and Numbers\n",
    "    tokens = [re.sub('[^A-Za-z]+', '', token) for token in tokens]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token, pos='v') for token in tokens]\n",
    "\n",
    "    # Spell Checking\n",
    "    spell = Speller(lang='en')\n",
    "    tokens = [spell(token) for token in tokens]\n",
    "    \n",
    "    # Joining the tokens back into a string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "    print(preprocessed_text)\n",
    "    \n",
    "    \n",
    "cleaned_text2 = preprocess_text(text)\n",
    "print(cleaned_text2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a8d2b-19a1-4e9a-8282-3974daa021c2",
   "metadata": {},
   "source": [
    "# Text For testing purposes\n",
    "text = \"\"\"Behind the Desk: Why Your Employee Could Be Your\n",
    "Risky Bet!\n",
    "Did you ever heard about Insider Risk?\n",
    "in today's digital world, companies are aware and ready for variety range of cybersecurity risks,\n",
    "like Malware attack, Distributed denial of service (DDoS), zero day vulnerabilities or any kind of\n",
    "cybersecurity attacks. although if you noticed these are list of well-recognized external threats.\n",
    "but most of companies are forgetting to add the insider risk in the list of Cybersecurity risks, it's\n",
    "important to not overlook risk posed by insiders within the organization. Insider risks, combines\n",
    "both intentional and unintentional actions done by empoyee, contractor or other party, that’s\n",
    "effect organization people, data or resources negatively.\n",
    "So typically, Insider Risk: a risk raised by employee, contractor, or other party to negatively\n",
    "affect organization people, data or resources, either by intentional or unintentional actions.\n",
    "Why its matter?\n",
    "You may ask why insider risk is matter, lets me give a short store about insider risk at Airline Company,\n",
    "Pegasus Airline left 23 million files containing personal data exposed online after an employee\n",
    "improperly configured a database. The incident was reported in June 2022 after the Turkish airline\n",
    "discovered the error. But I’m sure that you now that the store did not end here, as a consequence of this\n",
    "accident, company lost millions of dollars, brand awareness, customer lose trust in the brand, paid a fine\n",
    "for non-compliance with IT requirements, stalled data, etc.\n",
    "What are the different types of insider threats?\n",
    "The different type of insider threats is primarily based on individuals' roles and responsibilities.\n",
    "current employees, former employee, covert agents (moles). Every type of the above has a\n",
    "distinct motivation for attacking, such stealing sensitive data or valuable data for financial gain,\n",
    "sabotaging, or damaging as a form of revenge or personal gain, steal trade secret to limit a\n",
    "company competitive advantage, etc. Recognizing these people is must for organizations to\n",
    "implement strong security measures, monitor activities, and mitigate the risks created by insider\n",
    "threats.\n",
    "Note that not all insider threats are malicious, it could be an accident, but this accident may case\n",
    "a significant risk.\n",
    "What are the warning signs that could indicate an insider threat?\n",
    "Why is access control important for insider threat?\n",
    "To effectively control insider risks, Access control is crucial part. with some principle like,\n",
    " Role-based access control, that insure everyone have just permission aligned with their\n",
    "department and work responsibilities.\n",
    " least-privilege access, employees are restricted from accessing the network to only what\n",
    "they need to carry out for their responsibilities.\n",
    " zero trust security, verifies identities even within the network, to limit user and devices\n",
    "access.\n",
    "Therefore, reducing potential damage from insider threats.\n",
    "With time the effect of insiders’ threats are increasing from the side of cost and also the\n",
    "consequences of this event, as evidence se the fowling chart.\n",
    "total average cost of insider threats incidents,\n",
    "What are the consequences of barely manage insider risks?\n",
    "The consequences of a race but the most popular are financial loses, loss of intellectual property,\n",
    "reputational losses, operational destruction.\n",
    "In conclusion, organizations must remain alert in determining and mitigating insider risks, as\n",
    "these threats can arise from trusted individuals and have dangerous consequences. Effective\n",
    "management and security measures are must to deal with these threats successfully.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d29e6-9eea-4cbc-b2d1-e635f9cef7a0",
   "metadata": {},
   "source": [
    "# llama3_model\n",
    "\n",
    "please make sure to download llama3_model in your laptop before runing this code, use this link to download llama3\n",
    "\n",
    "download ollama linke:https://ollama.com\n",
    "\n",
    "Llama3 link: https://ollama.com/library/llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c389c28-a16c-4363-a2ed-10036750ccf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: /Users/raghad_alsaif/Applications/Ollama.app/Contents/MacOS/Ollama: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'/Users/raghad_alsaif/Applications/Ollama.app/Contents/MacOS/Ollama\\n\\n\\n\\n\\n\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_cell_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbash\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/raghad_alsaif/Applications/Ollama.app/Contents/MacOS/Ollama\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/IPython/core/magics/script.py:154\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshebang(line, cell)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/IPython/core/magics/script.py:314\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'/Users/raghad_alsaif/Applications/Ollama.app/Contents/MacOS/Ollama\\n\\n\\n\\n\\n\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/Users/raghad_alsaif/Applications/Ollama.app/Contents/MacOS/Ollama\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95443474-c006-456d-aeeb-a5977ea51128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the Llama3 model (this code might vary depending on how you've downloaded and installed the model)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import ollama \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Llama3Model\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define the prompt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mYou will be provided with article text delimited by triple quotes create a presentation content with the following format: \u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m1- Create a title for this article, based on the content of the text. \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m   And you could assume that slide_1 Content: is the title, slide_2 Content: is bullet points with the title of the bullet point, slide_3 Content: numbering points with the title of the numbering, slide_n Content: this point can be either pointers or numbering or a paragraph depending on the content. \u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m   The slide before the last slide should be: Conclusion, and the last slide should be:form the aritical text\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama2'"
     ]
    }
   ],
   "source": [
    "# Load the Llama3 model (this code might vary depending on how you've downloaded and installed the model)\n",
    "import ollama \n",
    "\n",
    "from llama3 import Llama3Model\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "You will be provided with article text delimited by triple quotes create a presentation content with the following format: \n",
    "1- Create a title for this article, based on the content of the text. \n",
    "2- Summarize the following text and create bullet points (these points can be either pointers or numbering or a paragraph depending on the content). \n",
    "3- Create a tagline for the text. \n",
    "4- Determine the article type (tech, health, business, marketing, etc.). \n",
    "5- Calculate the number of slides. \n",
    "6- Output a JSON object that contains the following keys: \n",
    "   - Title\n",
    "   - slide_1 Content\n",
    "   - slide_2 Content\n",
    "   - slide_n Content\n",
    "   - tagline\n",
    "   - article_type\n",
    "   - slide_number \n",
    "   and the value of each key will be with in string. \n",
    "   If the text does not contain an article to make a presentation from, then simply write No content provided. \n",
    "   Use the following format: \n",
    "   Title: ‹title to be generated› \n",
    "   slide_1 Content: <summary> \n",
    "   slide_2 Content: <slide 2 Content bullet points> \n",
    "   slide_n Content: <slide_n Content bullet points> \n",
    "   tagline: <tagline> \n",
    "   article_type: <article-type> \n",
    "   Slides_Number: <Slides_Number> \n",
    "   Output JSON: <JSON with summary Title, slide_1 Content, slide_2 Content, slide_n Content, tagline, article_type, slide_number>\n",
    "   Please note that slide_1 Content, slide_2 Content, slide_n Content is in sequence of numbers, so based on the content provided, assume what is the best number of slides and fill every slide with different content. \n",
    "   Slides should be like this: slide1, slide2, slide3, slide4, slide5, etc. \n",
    "   And you could assume that slide_1 Content: is the title, slide_2 Content: is bullet points with the title of the bullet point, slide_3 Content: numbering points with the title of the numbering, slide_n Content: this point can be either pointers or numbering or a paragraph depending on the content. \n",
    "   The slide before the last slide should be: Conclusion, and the last slide should be:form the aritical text\"\"\"\n",
    "\n",
    "# Define the preprocessed text (you should replace this with your preprocessed text)\n",
    "preprocessed_text = \"Your preprocessed article text here\"\n",
    "\n",
    "# Initialize the Llama3 model\n",
    "llama_model = Llama3Model()\n",
    "\n",
    "# Generate output using the Llama3 model\n",
    "output = llama_model.generate(prompt + f\"article_text= {preprocessed_text}'''\")\n",
    "\n",
    "# Print the generated output\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e834e-7695-4991-bda1-6d34c8c52b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedeabd7-eba9-4043-a3e7-90042111b005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
